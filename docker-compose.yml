services:
  mlflow-db:
    image: postgres:15
    restart: always
    environment:
      POSTGRES_USER: ${POSTGRES_USER}
      POSTGRES_PASSWORD: ${POSTGRES_PASSWORD}
      POSTGRES_DB: ${POSTGRES_DB}
    ports:
      - "${POSTGRES_PORT}:5432"
    volumes:
      - ./pgdata:/var/lib/postgresql/data

  airflow-db:
    image: postgres:15
    restart: always
    environment:
      POSTGRES_USER: ${AIRFLOW_DB_USER}
      POSTGRES_PASSWORD: ${AIRFLOW_DB_PASSWORD}
      POSTGRES_DB: ${AIRFLOW_DB_NAME}
    ports:
      - "${AIRFLOW_DB_PORT}:5432"
    volumes:
      - mlops_airflow_db_data:/var/lib/postgresql/data

  app-db:
    image: postgres:15
    restart: always
    environment:
      POSTGRES_USER: ${APP_DB_USER}
      POSTGRES_PASSWORD: ${APP_DB_PASSWORD}
      POSTGRES_DB: ${APP_DB_NAME}
    ports:
      - "${APP_DB_PORT}:5432"
    volumes:
      - mlops_app_db_data:/var/lib/postgresql/data

  minio:
    image: minio/minio:latest
    restart: always
    command: server /data --address ":9000" --console-address ":9023"
    environment:
      MINIO_ROOT_USER: ${MINIO_ROOT_USER}
      MINIO_ROOT_PASSWORD: ${MINIO_ROOT_PASSWORD}
    ports:
      - "${MINIO_PORT}:9000"
      - "${MINIO_CONSOLE_PORT}:9023"
    volumes:
      - mlops_minio_data:/data

  minio-init:
    image: minio/mc:latest
    depends_on:
      - minio
    entrypoint: >
      /bin/sh -c "
      sleep 3;
      mc alias set local http://minio:9000 ${MINIO_ROOT_USER} ${MINIO_ROOT_PASSWORD};
      mc mb --ignore-existing local/${S3_ARTIFACT_BUCKET};
      mc anonymous set download local/${S3_ARTIFACT_BUCKET};
      "

  mlflow:
    build: .
    restart: always
    depends_on:
      - mlflow-db
      - minio
      - minio-init
    environment:
      POSTGRES_URI: ${MLFLOW_POSTGRES_URI}
      ARTIFACT_ROOT: ${ARTIFACT_ROOT}
      MLFLOW_S3_ENDPOINT_URL: ${MLFLOW_S3_ENDPOINT_URL}
      AWS_ACCESS_KEY_ID: ${AWS_ACCESS_KEY_ID}
      AWS_SECRET_ACCESS_KEY: ${AWS_SECRET_ACCESS_KEY}
      MLFLOW_SERVER_ALLOWED_HOSTS: ${MLFLOW_SERVER_ALLOWED_HOSTS}
    ports:
      - "${MLFLOW_PORT}:5000"

  airflow-init:
    build:
      context: .
      dockerfile: Dockerfile.airflow
    depends_on:
      - airflow-db
    environment:
      AIRFLOW__CORE__EXECUTOR: LocalExecutor
      AIRFLOW__CORE__LOAD_EXAMPLES: "False"
      AIRFLOW__DATABASE__SQL_ALCHEMY_CONN: ${AIRFLOW_DB_URI}
      AIRFLOW__WEBSERVER__SECRET_KEY: ${AIRFLOW_SECRET_KEY}
      MLFLOW_TRACKING_URI: ${MLFLOW_TRACKING_URI}
      MLFLOW_S3_ENDPOINT_URL: ${MLFLOW_S3_ENDPOINT_URL}
      AWS_ACCESS_KEY_ID: ${AWS_ACCESS_KEY_ID}
      AWS_SECRET_ACCESS_KEY: ${AWS_SECRET_ACCESS_KEY}
      S3_ARTIFACT_BUCKET: ${S3_ARTIFACT_BUCKET}
    volumes:
      - ./airflow/dags:/opt/airflow/dags
      - ./src:/opt/airflow/src
    entrypoint: /bin/sh
    command: -c "airflow db init && airflow users create --role Admin --username ${AIRFLOW_ADMIN_USER} --password ${AIRFLOW_ADMIN_PASSWORD} --firstname Admin --lastname User --email admin@example.com || true"

  airflow-webserver:
    build:
      context: .
      dockerfile: Dockerfile.airflow
    depends_on:
      - airflow-db
      - airflow-init
    environment:
      AIRFLOW__CORE__EXECUTOR: LocalExecutor
      AIRFLOW__CORE__LOAD_EXAMPLES: "False"
      AIRFLOW__CORE__DAGS_ARE_PAUSED_AT_CREATION: "False"
      AIRFLOW__DATABASE__SQL_ALCHEMY_CONN: ${AIRFLOW_DB_URI}
      AIRFLOW__WEBSERVER__SECRET_KEY: ${AIRFLOW_SECRET_KEY}
      PYTHONPATH: /opt/airflow/src
      MLFLOW_TRACKING_URI: ${MLFLOW_TRACKING_URI}
      MLFLOW_S3_ENDPOINT_URL: ${MLFLOW_S3_ENDPOINT_URL}
      AWS_ACCESS_KEY_ID: ${AWS_ACCESS_KEY_ID}
      AWS_SECRET_ACCESS_KEY: ${AWS_SECRET_ACCESS_KEY}
      S3_ARTIFACT_BUCKET: ${S3_ARTIFACT_BUCKET}
    volumes:
      - ./airflow/dags:/opt/airflow/dags
      - ./src:/opt/airflow/src
    ports:
      - "${AIRFLOW_WEB_PORT}:8080"
    command: webserver

  airflow-scheduler:
    build:
      context: .
      dockerfile: Dockerfile.airflow
    depends_on:
      - airflow-db
      - airflow-init
    environment:
      AIRFLOW__CORE__EXECUTOR: LocalExecutor
      AIRFLOW__CORE__LOAD_EXAMPLES: "False"
      AIRFLOW__DATABASE__SQL_ALCHEMY_CONN: ${AIRFLOW_DB_URI}
      PYTHONPATH: /opt/airflow/src
      MLFLOW_TRACKING_URI: ${MLFLOW_TRACKING_URI}
      MLFLOW_S3_ENDPOINT_URL: ${MLFLOW_S3_ENDPOINT_URL}
      AWS_ACCESS_KEY_ID: ${AWS_ACCESS_KEY_ID}
      AWS_SECRET_ACCESS_KEY: ${AWS_SECRET_ACCESS_KEY}
      S3_ARTIFACT_BUCKET: ${S3_ARTIFACT_BUCKET}
    volumes:
      - ./airflow/dags:/opt/airflow/dags
      - ./src:/opt/airflow/src
    command: scheduler


  model-server:
    build:
      context: .
      dockerfile: Dockerfile.model
    restart: always
    depends_on:
      - mlflow
      - app-db
    environment:
      MLFLOW_TRACKING_URI: ${MLFLOW_TRACKING_URI}
      MLFLOW_S3_ENDPOINT_URL: ${MLFLOW_S3_ENDPOINT_URL}
      AWS_ACCESS_KEY_ID: ${AWS_ACCESS_KEY_ID}
      AWS_SECRET_ACCESS_KEY: ${AWS_SECRET_ACCESS_KEY}
      MODEL_ALIAS: ${MODEL_ALIAS}
      MODEL_ROLE: ${MODEL_ROLE}
      MODEL_SERVER_POLL_SECONDS: ${MODEL_SERVER_POLL_SECONDS}
      MODEL_NAME: ${MODEL_NAME}
    ports:
      - "${MODEL_SERVER_PORT}:8000"

  tag-watcher:
    build:
      context: .
      dockerfile: Dockerfile.watcher
    restart: always
    depends_on:
      - mlflow
    environment:
      MLFLOW_TRACKING_URI: ${MLFLOW_TRACKING_URI}
      MODEL_NAME: ${MODEL_NAME}
      WATCH_ALIASES: dev,test,Production
      POLL_SECONDS: 20
    ports:
      - "${TAG_WATCHER_PORT}:8000"

  prometheus:
    image: prom/prometheus:v2.53.2
    restart: always
    volumes:
      - ./monitoring/prometheus/prometheus.yml:/etc/prometheus/prometheus.yml
    ports:
      - "${PROMETHEUS_PORT}:9090"

  grafana:
    image: grafana/grafana:11.4.0
    restart: always
    environment:
      GF_SECURITY_ADMIN_USER: ${GRAFANA_ADMIN_USER}
      GF_SECURITY_ADMIN_PASSWORD: ${GRAFANA_ADMIN_PASSWORD}
    volumes:
      - mlops_grafana_data:/var/lib/grafana
      - ./monitoring/grafana/provisioning:/etc/grafana/provisioning
      - ./monitoring/grafana/dashboards:/etc/grafana/dashboards
    ports:
      - "${GRAFANA_PORT}:3000"
    depends_on:
      - prometheus


volumes:
  mlops_airflow_db_data:
  mlops_app_db_data:
  mlops_minio_data:
  mlops_grafana_data:
