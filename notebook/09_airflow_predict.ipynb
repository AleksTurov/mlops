{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "cfb4f632",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "94243bc9",
   "metadata": {},
   "source": [
    "# Получение предсказаний по модели "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ae9b81e",
   "metadata": {},
   "source": [
    "## Импортируем необходимые библиотеки"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1c81ed3",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-11-10 11:01:49,063 | my_logger - INFO - ✅ PostgreSQL engine создан | /data/aturov/scoring/src/database.py:21\n",
      "2025-11-10 11:01:49,088 | my_logger - INFO - ✅ ClickHouse engine создан | /data/aturov/scoring/src/database.py:36\n",
      "2025-11-10 11:01:49,089 | my_logger - INFO - ✅ IPDR ClickHouse engine создан | /data/aturov/scoring/src/database.py:46\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Configuration loaded successfully.\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "import pandas as pd, pyarrow\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import os, sys\n",
    "import mlflow\n",
    "\n",
    "from torch.utils.data import DataLoader\n",
    "import boto3\n",
    "import io\n",
    "import torch\n",
    "\n",
    "from pathlib import Path\n",
    "from datetime import date, timedelta, datetime\n",
    "from dotenv import load_dotenv\n",
    "from mlflow.tracking import MlflowClient\n",
    "import ast\n",
    "import joblib\n",
    "from sqlalchemy import text\n",
    "\n",
    "# --- Настройка путей и sys.path ---\n",
    "# Добавляем корневую директорию проекта в sys.path для импорта кастомных модулей\n",
    "PROJECT_ROOT = Path().cwd().parent\n",
    "if str(PROJECT_ROOT) not in sys.path:\n",
    "    sys.path.append(str(PROJECT_ROOT))\n",
    "\n",
    "from src.config import config\n",
    "from src.logger import logger\n",
    "from src.database import clickhouse_engine, postgres_engine, ipdr_engine    \n",
    "from src.visualization import *\n",
    "from src.predprocessing_lstm import _process_group, create_lstm_sequences_credit_scoring, convert_categorical_to_str, collate_fn\n",
    "from src.base_models import LSTMCreditScoringDataset\n",
    "from src.modeling_lstm import _predict_probs_from_loader\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "55b143ea",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-11-10 11:01:50,185 | my_logger - INFO - Using device: cuda | /tmp/ipykernel_3121082/134817763.py:4\n"
     ]
    }
   ],
   "source": [
    "# --- Настройка устройства для вычислений ---.\n",
    "device = torch.device(\"cuda\")\n",
    "\n",
    "logger.info(f\"Using device: {device}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "582b8273",
   "metadata": {},
   "source": [
    "## Mlflow\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b570ac23",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-11-10 11:01:50,225 | my_logger - INFO - MLflow client created and tracking URI set. | /tmp/ipykernel_3121082/2002293533.py:1\n"
     ]
    }
   ],
   "source": [
    "logger.info(\"MLflow client created and tracking URI set.\")\n",
    "\n",
    "mlflow.set_tracking_uri(config.mlflow_config.HOST_MLFLOW)\n",
    "\n",
    "\n",
    "client = MlflowClient()\n",
    "\n",
    "exp = client.get_experiment_by_name(config.mlflow_config.NAME_PROJECT)\n",
    "if exp is None:\n",
    "    # create_experiment поддерживает tags\n",
    "    try:\n",
    "        exp_id = client.create_experiment(config.mlflow_config.NAME_PROJECT, tags={\"model\": config.mlflow_config.NAME_MODEL_CLIENT})\n",
    "    except Exception:\n",
    "        # race: если кто-то создал эксперимент параллельно — получить его\n",
    "        exp = client.get_experiment_by_name(config.mlflow_config.NAME_PROJECT)\n",
    "        exp_id = exp.experiment_id if exp else None\n",
    "    if exp_id:\n",
    "        exp = client.get_experiment(exp_id)\n",
    "\n",
    "# установить/обновить теги и описание (описание в UI хранится как тег \"mlflow.note.content\")\n",
    "if exp is not None:\n",
    "    client.set_experiment_tag(exp.experiment_id, \"model\", config.mlflow_config.NAME_MODEL_CLIENT)\n",
    "    if config.mlflow_config.EXPERIMENT_DESCRIPTION:\n",
    "        client.set_experiment_tag(exp.experiment_id, \"mlflow.note.content\", config.mlflow_config.EXPERIMENT_DESCRIPTION)\n",
    "\n",
    "# сделать эксперимент активным\n",
    "mlflow.set_experiment(config.mlflow_config.NAME_PROJECT)\n",
    "exp_id = mlflow.get_experiment_by_name(config.mlflow_config.NAME_PROJECT).experiment_id\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "7315dc84",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-11-10 11:01:50,488 | my_logger - INFO - Найден run_id по алиасу 'test': ec0536e42419435895f30950d76e651a | /tmp/ipykernel_3121082/693350137.py:3\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<ModelVersion: aliases=['test'], creation_timestamp=1762402581652, current_stage='None', deployment_job_state=<ModelVersionDeploymentJobState: current_task_name='', job_id='', job_state='DEPLOYMENT_JOB_CONNECTION_STATE_UNSPECIFIED', run_id='', run_state='DEPLOYMENT_JOB_RUN_STATE_UNSPECIFIED'>, description='', last_updated_timestamp=1762402581652, metrics=None, model_id=None, name='LSTM_Scoring', params=None, run_id='ec0536e42419435895f30950d76e651a', run_link='', source='s3://mlflow/3/models/m-79d7885beb054a37b9285232c681fc6b/artifacts', status='READY', status_message=None, tags={}, user_id='', version='6'>"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "version_info = client.get_model_version_by_alias(name=config.mlflow_config.NAME_MODEL_CLIENT, alias='test')\n",
    "run_id = version_info.run_id\n",
    "logger.info(f\"Найден run_id по алиасу 'test': {run_id}\")\n",
    "version_info\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "8ef1dff1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('0.4601399004459381', '0.29767337441444397')"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "optimal_threshold = client.get_run(run_id).data.params.get('optimal_threshold')\n",
    "optimal_f1_threshold = client.get_run(run_id).data.params.get('optimal_f1_threshold')\n",
    "optimal_f1_threshold, optimal_threshold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "2e80e373",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-11-10 11:01:50,723 | my_logger - INFO - Текущая дата 20251110 больше даты сплита 2024-12-01 - дата обучающей выборки | /tmp/ipykernel_3121082/125430703.py:14\n"
     ]
    }
   ],
   "source": [
    "SPLINT_DATE = client.get_run(run_id).data.params.get('split_date')\n",
    "DATE_END = client.get_run(run_id).data.params.get('date_end')\n",
    "NAME_DATAFRAME = client.get_run(run_id).data.params.get('name_dataframe')\n",
    "COUNT_WEEKS = int(client.get_run(run_id).data.params.get('count_weeks'))\n",
    "OVERDUE_DAYS_MAX = int(client.get_run(run_id).data.params.get('overdue_days_max'))\n",
    "TOTAL_OVERDUE = int(client.get_run(run_id).data.params.get('total_overdue'))\n",
    "NAME_DATAFRAME_WEEKS = f'{NAME_DATAFRAME}_{COUNT_WEEKS}_{OVERDUE_DAYS_MAX}_{TOTAL_OVERDUE}' # имя файла с признаками по неделям for LSTMs models\n",
    "DATE_FEATURES = client.get_run(run_id).data.params.get('date_features')\n",
    "KEYS_COLUMNS = ast.literal_eval(client.get_run(run_id).data.params.get('name_columns'))\n",
    "CURRENT_DATE = datetime.now().strftime('%Y%m%d')\n",
    "\n",
    "\n",
    "if CURRENT_DATE > SPLINT_DATE:\n",
    "    logger.info(f\"Текущая дата {CURRENT_DATE} больше даты сплита {SPLINT_DATE} - дата обучающей выборки\")\n",
    "else:\n",
    "    logger.warning(f\"Текущая дата {CURRENT_DATE} меньше даты сплита {SPLINT_DATE} - дата обучающей выборки\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "d3d6414e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'features_weeks'"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "NAME_DATAFRAME"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "727510ad",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-11-10 11:01:50,876 | my_logger - INFO - Numeric cols: 16, categorical cols: 4 | /tmp/ipykernel_3121082/270943303.py:23\n"
     ]
    }
   ],
   "source": [
    "s3_client = boto3.client(\n",
    "    's3',\n",
    "    endpoint_url=config.mlflow_config.MINIO_ENDPOINT,\n",
    "    aws_access_key_id=config.mlflow_config.AWS_ACCESS_KEY_ID,\n",
    "    aws_secret_access_key=config.mlflow_config.AWS_SECRET_ACCESS_KEY,\n",
    ")\n",
    "\n",
    "def load_from_s3(bucket, key):\n",
    "    '''Загружает файл из S3 и возвращает его как BytesIO объект'''\n",
    "    response = s3_client.get_object(Bucket=bucket, Key=key)\n",
    "    data = response['Body'].read()\n",
    "    return io.BytesIO(data)\n",
    "\n",
    "# Загрузка файлов напрямую\n",
    "prefix = f\"{exp_id}/{run_id}/artifacts/preprocessor\"\n",
    "\n",
    "cat_maps = joblib.load(load_from_s3(config.mlflow_config.BUCKET_NAME, f\"{prefix}/cat_maps.pkl\"))\n",
    "preprocessor = joblib.load(load_from_s3(config.mlflow_config.BUCKET_NAME, f\"{prefix}/preprocessor_lstm_{DATE_FEATURES}.joblib\"))\n",
    "\n",
    "numeric_cols = joblib.load(load_from_s3(config.mlflow_config.BUCKET_NAME, f\"{prefix}/numeric_cols.pkl\"))\n",
    "categorical_cols = joblib.load(load_from_s3(config.mlflow_config.BUCKET_NAME, f\"{prefix}/categorical_cols.pkl\"))\n",
    "\n",
    "logger.info(f\"Numeric cols: {len(numeric_cols)}, categorical cols: {len(categorical_cols)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "d9fd771a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/data/aturov/scoring/.venv/lib/python3.10/site-packages/torch/cuda/__init__.py:827: UserWarning: Can't initialize NVML\n",
      "  warnings.warn(\"Can't initialize NVML\")\n",
      "2025-11-10 11:01:51,118 | my_logger - INFO - Loaded model: LSTMModel(\n",
      "  (embs): ModuleList(\n",
      "    (0): Embedding(5, 2)\n",
      "    (1): Embedding(6, 2)\n",
      "    (2): Embedding(13, 3)\n",
      "    (3): Embedding(5, 2)\n",
      "  )\n",
      "  (lstm): LSTM(25, 128, batch_first=True, dropout=0.3)\n",
      "  (dropout): Dropout(p=0.3, inplace=False)\n",
      "  (fc): Linear(in_features=128, out_features=1, bias=True)\n",
      ") | /tmp/ipykernel_3121082/1697114400.py:6\n"
     ]
    }
   ],
   "source": [
    "model_key = version_info.source.replace(f's3://{config.mlflow_config.BUCKET_NAME}/', '') + '/data/model.pth'\n",
    "\n",
    "response = s3_client.get_object(Bucket=config.mlflow_config.BUCKET_NAME, Key=model_key)\n",
    "model_buffer = io.BytesIO(response['Body'].read())\n",
    "model = torch.load(model_buffer, map_location=device, weights_only=False)\n",
    "logger.info(f\"Loaded model: {model}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "9b0b049b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['days_from_dt_end_to_price_change_date',\n",
       " 'FLAG_DEVICE_4G',\n",
       " 'days_from_dt_end_to_date_lad',\n",
       " 'USAGE_INTERNET_NIGHT',\n",
       " 'ACTIVE_IND',\n",
       " 'REGION_CELL',\n",
       " 'days_from_dt_end_to_act_date',\n",
       " 'REVENUE_ABONKA',\n",
       " 'GENDER',\n",
       " 'BALANCE_END',\n",
       " 'USAGE_INTERNET_LTE',\n",
       " 'COUNT_RECHARGE',\n",
       " 'LIFETIME_TOTAL',\n",
       " 'USAGE_ABONKA_TP',\n",
       " 'INTERCONNECT_MN_IN',\n",
       " 'USAGE_INTERNET_3G_FREE',\n",
       " 'days_from_dt_end_to_date_contract',\n",
       " 'USAGE_NUM_INTERNET_PAK',\n",
       " 'REVENUE_INTERNET_PAYG',\n",
       " 'USAGE_OUT_INT_VOICE_RUSSIA']"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "KEYS_COLUMNS"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c6f9b715",
   "metadata": {},
   "source": [
    "## Загрузка клиентов и фичей для предсказания"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "ed8a152d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_query(engine, number_weeks):\n",
    "    \"\"\"\n",
    "    Возвращает только нужные KEYS_COLUMNS из DWH.dm_datamart_weekly.\n",
    "    Для days_from_dt_end_to_* считаем: dateDiff('day', <DATE_COL>, addDays(DT, 7))\n",
    "    \"\"\"\n",
    "    computed = {\n",
    "        'days_from_dt_end_to_price_change_date': \"coalesce(dateDiff('day', PRICE_CHANGE_DATE, addDays(DT, 7)), -1) AS days_from_dt_end_to_price_change_date\",\n",
    "        'days_from_dt_end_to_act_date':          \"coalesce(dateDiff('day', ACT_DATE,          addDays(DT, 7)), -1) AS days_from_dt_end_to_act_date\",\n",
    "        'days_from_dt_end_to_date_contract':     \"coalesce(dateDiff('day', DATE_CONTRACT,     addDays(DT, 7)), -1) AS days_from_dt_end_to_date_contract\",\n",
    "        'days_from_dt_end_to_date_lad':          \"coalesce(dateDiff('day', DATE_LAD,          addDays(DT, 7)), -1) AS days_from_dt_end_to_date_lad\",\n",
    "        'days_from_dt_end_to_date_inactive':      \"coalesce(dateDiff('day', DATE_INACTIVE,     addDays(DT, 7)), -1) AS days_from_dt_end_to_date_inactive\",\n",
    "        'days_from_dt_end_to_date_abonka':        \"coalesce(dateDiff('day', DATE_ABONKA,       addDays(DT, 7)), -1) AS days_from_dt_end_to_date_abonka\",\n",
    "    \n",
    "    }\n",
    "\n",
    "    select_items = []\n",
    "    for col in KEYS_COLUMNS:  # KEYS_COLUMNS уже загружается выше из MLflow\n",
    "        if col in computed:\n",
    "            select_items.append(computed[col])\n",
    "        else:\n",
    "            select_items.append(col)\n",
    "    select_items.append('CTN as ctn, SUBS_ID as subs_id')  # Добавляем колонку DT для фильтрации по дате\n",
    "    select_clause = \",\\n                \".join(select_items)\n",
    "    query = f\"\"\"\n",
    "        SELECT\n",
    "                {select_clause}\n",
    "        FROM DWH.dm_datamart_weekly w\n",
    "        where w.DT <= toDate('{CURRENT_DATE}')\n",
    "          AND w.DT = toStartOfWeek('{CURRENT_DATE}' - INTERVAL {number_weeks} WEEK - INTERVAL 1 DAY, 1) \n",
    "          limit 10000\n",
    "    \"\"\"\n",
    "\n",
    "    df = pd.read_sql(query, engine)\n",
    "    logger.info(f\"Loaded data for {number_weeks} weeks: {df.shape}\")\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "f98ccdf0",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-11-10 11:01:51,214 | my_logger - INFO - COUNT_WEEKS = 1 | /tmp/ipykernel_3121082/115029470.py:3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-11-10 11:01:51,505 | my_logger - INFO - Loaded data for 1 weeks: (10000, 22) | /tmp/ipykernel_3121082/1495415186.py:34\n",
      "2025-11-10 11:01:51,507 | my_logger - INFO - COUNT_WEEKS = 1, shape = (10000, 23) | /tmp/ipykernel_3121082/115029470.py:9\n",
      "2025-11-10 11:01:51,507 | my_logger - INFO - COUNT_WEEKS = 2 | /tmp/ipykernel_3121082/115029470.py:3\n",
      "2025-11-10 11:01:51,723 | my_logger - INFO - Loaded data for 2 weeks: (10000, 22) | /tmp/ipykernel_3121082/1495415186.py:34\n",
      "2025-11-10 11:01:51,724 | my_logger - INFO - COUNT_WEEKS = 2, shape = (10000, 23) | /tmp/ipykernel_3121082/115029470.py:9\n",
      "2025-11-10 11:01:51,725 | my_logger - INFO - COUNT_WEEKS = 3 | /tmp/ipykernel_3121082/115029470.py:3\n",
      "2025-11-10 11:01:51,942 | my_logger - INFO - Loaded data for 3 weeks: (10000, 22) | /tmp/ipykernel_3121082/1495415186.py:34\n",
      "2025-11-10 11:01:51,943 | my_logger - INFO - COUNT_WEEKS = 3, shape = (10000, 23) | /tmp/ipykernel_3121082/115029470.py:9\n",
      "2025-11-10 11:01:51,943 | my_logger - INFO - COUNT_WEEKS = 4 | /tmp/ipykernel_3121082/115029470.py:3\n",
      "2025-11-10 11:01:52,152 | my_logger - INFO - Loaded data for 4 weeks: (10000, 22) | /tmp/ipykernel_3121082/1495415186.py:34\n",
      "2025-11-10 11:01:52,153 | my_logger - INFO - COUNT_WEEKS = 4, shape = (10000, 23) | /tmp/ipykernel_3121082/115029470.py:9\n",
      "2025-11-10 11:01:52,154 | my_logger - INFO - COUNT_WEEKS = 5 | /tmp/ipykernel_3121082/115029470.py:3\n",
      "2025-11-10 11:01:52,548 | my_logger - INFO - Loaded data for 5 weeks: (10000, 22) | /tmp/ipykernel_3121082/1495415186.py:34\n",
      "2025-11-10 11:01:52,550 | my_logger - INFO - COUNT_WEEKS = 5, shape = (10000, 23) | /tmp/ipykernel_3121082/115029470.py:9\n",
      "2025-11-10 11:01:52,550 | my_logger - INFO - COUNT_WEEKS = 6 | /tmp/ipykernel_3121082/115029470.py:3\n",
      "2025-11-10 11:01:52,759 | my_logger - INFO - Loaded data for 6 weeks: (10000, 22) | /tmp/ipykernel_3121082/1495415186.py:34\n",
      "2025-11-10 11:01:52,760 | my_logger - INFO - COUNT_WEEKS = 6, shape = (10000, 23) | /tmp/ipykernel_3121082/115029470.py:9\n",
      "2025-11-10 11:01:52,760 | my_logger - INFO - COUNT_WEEKS = 7 | /tmp/ipykernel_3121082/115029470.py:3\n",
      "2025-11-10 11:01:52,979 | my_logger - INFO - Loaded data for 7 weeks: (10000, 22) | /tmp/ipykernel_3121082/1495415186.py:34\n",
      "2025-11-10 11:01:52,980 | my_logger - INFO - COUNT_WEEKS = 7, shape = (10000, 23) | /tmp/ipykernel_3121082/115029470.py:9\n",
      "2025-11-10 11:01:52,981 | my_logger - INFO - COUNT_WEEKS = 8 | /tmp/ipykernel_3121082/115029470.py:3\n",
      "2025-11-10 11:01:53,201 | my_logger - INFO - Loaded data for 8 weeks: (10000, 22) | /tmp/ipykernel_3121082/1495415186.py:34\n",
      "2025-11-10 11:01:53,202 | my_logger - INFO - COUNT_WEEKS = 8, shape = (10000, 23) | /tmp/ipykernel_3121082/115029470.py:9\n",
      "2025-11-10 11:01:53,203 | my_logger - INFO - COUNT_WEEKS = 9 | /tmp/ipykernel_3121082/115029470.py:3\n",
      "2025-11-10 11:01:53,427 | my_logger - INFO - Loaded data for 9 weeks: (10000, 22) | /tmp/ipykernel_3121082/1495415186.py:34\n",
      "2025-11-10 11:01:53,428 | my_logger - INFO - COUNT_WEEKS = 9, shape = (10000, 23) | /tmp/ipykernel_3121082/115029470.py:9\n",
      "2025-11-10 11:01:53,428 | my_logger - INFO - COUNT_WEEKS = 10 | /tmp/ipykernel_3121082/115029470.py:3\n",
      "2025-11-10 11:01:53,628 | my_logger - INFO - Loaded data for 10 weeks: (10000, 22) | /tmp/ipykernel_3121082/1495415186.py:34\n",
      "2025-11-10 11:01:53,629 | my_logger - INFO - COUNT_WEEKS = 10, shape = (10000, 23) | /tmp/ipykernel_3121082/115029470.py:9\n",
      "2025-11-10 11:01:53,630 | my_logger - INFO - COUNT_WEEKS = 11 | /tmp/ipykernel_3121082/115029470.py:3\n",
      "2025-11-10 11:01:53,847 | my_logger - INFO - Loaded data for 11 weeks: (10000, 22) | /tmp/ipykernel_3121082/1495415186.py:34\n",
      "2025-11-10 11:01:53,848 | my_logger - INFO - COUNT_WEEKS = 11, shape = (10000, 23) | /tmp/ipykernel_3121082/115029470.py:9\n",
      "2025-11-10 11:01:53,848 | my_logger - INFO - COUNT_WEEKS = 12 | /tmp/ipykernel_3121082/115029470.py:3\n",
      "2025-11-10 11:01:54,061 | my_logger - INFO - Loaded data for 12 weeks: (10000, 22) | /tmp/ipykernel_3121082/1495415186.py:34\n",
      "2025-11-10 11:01:54,062 | my_logger - INFO - COUNT_WEEKS = 12, shape = (10000, 23) | /tmp/ipykernel_3121082/115029470.py:9\n",
      "2025-11-10 11:01:54,081 | my_logger - INFO - Final features shape: (120000, 23) | /tmp/ipykernel_3121082/115029470.py:12\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>days_from_dt_end_to_price_change_date</th>\n",
       "      <th>FLAG_DEVICE_4G</th>\n",
       "      <th>days_from_dt_end_to_date_lad</th>\n",
       "      <th>USAGE_INTERNET_NIGHT</th>\n",
       "      <th>ACTIVE_IND</th>\n",
       "      <th>REGION_CELL</th>\n",
       "      <th>days_from_dt_end_to_act_date</th>\n",
       "      <th>REVENUE_ABONKA</th>\n",
       "      <th>GENDER</th>\n",
       "      <th>BALANCE_END</th>\n",
       "      <th>...</th>\n",
       "      <th>USAGE_ABONKA_TP</th>\n",
       "      <th>INTERCONNECT_MN_IN</th>\n",
       "      <th>USAGE_INTERNET_3G_FREE</th>\n",
       "      <th>days_from_dt_end_to_date_contract</th>\n",
       "      <th>USAGE_NUM_INTERNET_PAK</th>\n",
       "      <th>REVENUE_INTERNET_PAYG</th>\n",
       "      <th>USAGE_OUT_INT_VOICE_RUSSIA</th>\n",
       "      <th>ctn</th>\n",
       "      <th>subs_id</th>\n",
       "      <th>count_weeks</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>83</td>\n",
       "      <td></td>\n",
       "      <td>-1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td></td>\n",
       "      <td>83</td>\n",
       "      <td>0.0</td>\n",
       "      <td></td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>83</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>996774049151</td>\n",
       "      <td>21590845</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>83</td>\n",
       "      <td></td>\n",
       "      <td>-1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td></td>\n",
       "      <td>83</td>\n",
       "      <td>0.0</td>\n",
       "      <td></td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>83</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>996774049152</td>\n",
       "      <td>21590848</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>83</td>\n",
       "      <td></td>\n",
       "      <td>-1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td></td>\n",
       "      <td>83</td>\n",
       "      <td>0.0</td>\n",
       "      <td></td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>83</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>996774049158</td>\n",
       "      <td>21590866</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3 rows × 23 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   days_from_dt_end_to_price_change_date FLAG_DEVICE_4G  \\\n",
       "0                                     83                  \n",
       "1                                     83                  \n",
       "2                                     83                  \n",
       "\n",
       "   days_from_dt_end_to_date_lad  USAGE_INTERNET_NIGHT  ACTIVE_IND REGION_CELL  \\\n",
       "0                            -1                   0.0           0               \n",
       "1                            -1                   0.0           0               \n",
       "2                            -1                   0.0           0               \n",
       "\n",
       "   days_from_dt_end_to_act_date  REVENUE_ABONKA GENDER  BALANCE_END  ...  \\\n",
       "0                            83             0.0                 0.0  ...   \n",
       "1                            83             0.0                 0.0  ...   \n",
       "2                            83             0.0                 0.0  ...   \n",
       "\n",
       "   USAGE_ABONKA_TP  INTERCONNECT_MN_IN  USAGE_INTERNET_3G_FREE  \\\n",
       "0                0                 0.0                     0.0   \n",
       "1                0                 0.0                     0.0   \n",
       "2                0                 0.0                     0.0   \n",
       "\n",
       "   days_from_dt_end_to_date_contract  USAGE_NUM_INTERNET_PAK  \\\n",
       "0                                 83                       0   \n",
       "1                                 83                       0   \n",
       "2                                 83                       0   \n",
       "\n",
       "   REVENUE_INTERNET_PAYG  USAGE_OUT_INT_VOICE_RUSSIA           ctn   subs_id  \\\n",
       "0                    0.0                         0.0  996774049151  21590845   \n",
       "1                    0.0                         0.0  996774049152  21590848   \n",
       "2                    0.0                         0.0  996774049158  21590866   \n",
       "\n",
       "   count_weeks  \n",
       "0            1  \n",
       "1            1  \n",
       "2            1  \n",
       "\n",
       "[3 rows x 23 columns]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_features_parts = []\n",
    "for number_week in range(1, COUNT_WEEKS+1):  # от 1 до 12 недель включительно\n",
    "    logger.info(f\"COUNT_WEEKS = {number_week}\")\n",
    "    df_part = make_query(clickhouse_engine, number_weeks=number_week)\n",
    "    if df_part is None or df_part.empty:\n",
    "        logger.warning(f\"COUNT_WEEKS = {number_week}, пустой датафрейм, пропускаем\")\n",
    "        continue\n",
    "    df_part[config.features.SEQ_COL] = number_week\n",
    "    logger.info(f\"COUNT_WEEKS = {number_week}, shape = {df_part.shape}\")\n",
    "    df_features_parts.append(df_part)\n",
    "df = pd.concat(df_features_parts, ignore_index=True)\n",
    "logger.info(f\"Final features shape: {df.shape}\")\n",
    "df.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "ed894cb1",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-11-10 11:01:54,143 | my_logger - INFO - After filtering by subs_id with count_weeks == 1, shape: (10000, 23) | /tmp/ipykernel_3121082/504841215.py:4\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>days_from_dt_end_to_price_change_date</th>\n",
       "      <th>FLAG_DEVICE_4G</th>\n",
       "      <th>days_from_dt_end_to_date_lad</th>\n",
       "      <th>USAGE_INTERNET_NIGHT</th>\n",
       "      <th>ACTIVE_IND</th>\n",
       "      <th>REGION_CELL</th>\n",
       "      <th>days_from_dt_end_to_act_date</th>\n",
       "      <th>REVENUE_ABONKA</th>\n",
       "      <th>GENDER</th>\n",
       "      <th>BALANCE_END</th>\n",
       "      <th>USAGE_INTERNET_LTE</th>\n",
       "      <th>COUNT_RECHARGE</th>\n",
       "      <th>LIFETIME_TOTAL</th>\n",
       "      <th>USAGE_ABONKA_TP</th>\n",
       "      <th>INTERCONNECT_MN_IN</th>\n",
       "      <th>USAGE_INTERNET_3G_FREE</th>\n",
       "      <th>days_from_dt_end_to_date_contract</th>\n",
       "      <th>USAGE_NUM_INTERNET_PAK</th>\n",
       "      <th>REVENUE_INTERNET_PAYG</th>\n",
       "      <th>USAGE_OUT_INT_VOICE_RUSSIA</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>subs_id</th>\n",
       "      <th>ctn</th>\n",
       "      <th>count_weeks</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>21590845</th>\n",
       "      <th>996774049151</th>\n",
       "      <th>1</th>\n",
       "      <td>83</td>\n",
       "      <td></td>\n",
       "      <td>-1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td></td>\n",
       "      <td>83</td>\n",
       "      <td>0.0</td>\n",
       "      <td></td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>83</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>83</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21590848</th>\n",
       "      <th>996774049152</th>\n",
       "      <th>1</th>\n",
       "      <td>83</td>\n",
       "      <td></td>\n",
       "      <td>-1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td></td>\n",
       "      <td>83</td>\n",
       "      <td>0.0</td>\n",
       "      <td></td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>83</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>83</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21590866</th>\n",
       "      <th>996774049158</th>\n",
       "      <th>1</th>\n",
       "      <td>83</td>\n",
       "      <td></td>\n",
       "      <td>-1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td></td>\n",
       "      <td>83</td>\n",
       "      <td>0.0</td>\n",
       "      <td></td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>83</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>83</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                   days_from_dt_end_to_price_change_date  \\\n",
       "subs_id  ctn          count_weeks                                          \n",
       "21590845 996774049151 1                                               83   \n",
       "21590848 996774049152 1                                               83   \n",
       "21590866 996774049158 1                                               83   \n",
       "\n",
       "                                  FLAG_DEVICE_4G  \\\n",
       "subs_id  ctn          count_weeks                  \n",
       "21590845 996774049151 1                            \n",
       "21590848 996774049152 1                            \n",
       "21590866 996774049158 1                            \n",
       "\n",
       "                                   days_from_dt_end_to_date_lad  \\\n",
       "subs_id  ctn          count_weeks                                 \n",
       "21590845 996774049151 1                                      -1   \n",
       "21590848 996774049152 1                                      -1   \n",
       "21590866 996774049158 1                                      -1   \n",
       "\n",
       "                                   USAGE_INTERNET_NIGHT  ACTIVE_IND  \\\n",
       "subs_id  ctn          count_weeks                                     \n",
       "21590845 996774049151 1                             0.0           0   \n",
       "21590848 996774049152 1                             0.0           0   \n",
       "21590866 996774049158 1                             0.0           0   \n",
       "\n",
       "                                  REGION_CELL  days_from_dt_end_to_act_date  \\\n",
       "subs_id  ctn          count_weeks                                             \n",
       "21590845 996774049151 1                                                  83   \n",
       "21590848 996774049152 1                                                  83   \n",
       "21590866 996774049158 1                                                  83   \n",
       "\n",
       "                                   REVENUE_ABONKA GENDER  BALANCE_END  \\\n",
       "subs_id  ctn          count_weeks                                       \n",
       "21590845 996774049151 1                       0.0                 0.0   \n",
       "21590848 996774049152 1                       0.0                 0.0   \n",
       "21590866 996774049158 1                       0.0                 0.0   \n",
       "\n",
       "                                   USAGE_INTERNET_LTE  COUNT_RECHARGE  \\\n",
       "subs_id  ctn          count_weeks                                       \n",
       "21590845 996774049151 1                           0.0               0   \n",
       "21590848 996774049152 1                           0.0               0   \n",
       "21590866 996774049158 1                           0.0               0   \n",
       "\n",
       "                                   LIFETIME_TOTAL  USAGE_ABONKA_TP  \\\n",
       "subs_id  ctn          count_weeks                                    \n",
       "21590845 996774049151 1                        83                0   \n",
       "21590848 996774049152 1                        83                0   \n",
       "21590866 996774049158 1                        83                0   \n",
       "\n",
       "                                   INTERCONNECT_MN_IN  USAGE_INTERNET_3G_FREE  \\\n",
       "subs_id  ctn          count_weeks                                               \n",
       "21590845 996774049151 1                           0.0                     0.0   \n",
       "21590848 996774049152 1                           0.0                     0.0   \n",
       "21590866 996774049158 1                           0.0                     0.0   \n",
       "\n",
       "                                   days_from_dt_end_to_date_contract  \\\n",
       "subs_id  ctn          count_weeks                                      \n",
       "21590845 996774049151 1                                           83   \n",
       "21590848 996774049152 1                                           83   \n",
       "21590866 996774049158 1                                           83   \n",
       "\n",
       "                                   USAGE_NUM_INTERNET_PAK  \\\n",
       "subs_id  ctn          count_weeks                           \n",
       "21590845 996774049151 1                                 0   \n",
       "21590848 996774049152 1                                 0   \n",
       "21590866 996774049158 1                                 0   \n",
       "\n",
       "                                   REVENUE_INTERNET_PAYG  \\\n",
       "subs_id  ctn          count_weeks                          \n",
       "21590845 996774049151 1                              0.0   \n",
       "21590848 996774049152 1                              0.0   \n",
       "21590866 996774049158 1                              0.0   \n",
       "\n",
       "                                   USAGE_OUT_INT_VOICE_RUSSIA  \n",
       "subs_id  ctn          count_weeks                              \n",
       "21590845 996774049151 1                                   0.0  \n",
       "21590848 996774049152 1                                   0.0  \n",
       "21590866 996774049158 1                                   0.0  "
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Получаем уникальные subs_id с count_weeks == 1 и оставляем только их для предсказаний\n",
    "sub_ids = df.query(f\"{config.features.SEQ_COL} == 1\")['subs_id'].unique()\n",
    "df = df[df['subs_id'].isin(sub_ids)].reset_index(drop=True)\n",
    "logger.info(f\"After filtering by subs_id with count_weeks == 1, shape: {df.shape}\")\n",
    "df.set_index(['subs_id', 'ctn', config.features.SEQ_COL], inplace=True)\n",
    "df.head(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7028025c",
   "metadata": {},
   "source": [
    "## Преобразование данных для предсказания"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "138c8dbe",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['FLAG_DEVICE_4G', 'ACTIVE_IND', 'REGION_CELL', 'GENDER']"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "categorical_cols"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "27bc44bf",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-11-10 11:01:54,227 | my_logger - INFO - Categorical columns converted to str | /data/aturov/scoring/src/predprocessing_lstm.py:90\n",
      "2025-11-10 11:01:54,228 | my_logger - INFO - ID columns for grouping: ['subs_id', 'ctn'] | /tmp/ipykernel_3121082/734171255.py:5\n"
     ]
    }
   ],
   "source": [
    "val_tab_full = convert_categorical_to_str(df, categorical_cols)\n",
    "# Определяем ID колонки для группировки\n",
    "id_cols_from_index = list(val_tab_full.index.names)\n",
    "id_cols = [col for col in id_cols_from_index if col not in [config.features.SEQ_COL, config.features.TARGET_COL]]\n",
    "logger.info(f\"ID columns for grouping: {id_cols}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "86de6290",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-11-10 11:01:54,891 | my_logger - INFO - Найдено 10000 уникальных групп для обработки на нескольких ядрах. | /data/aturov/scoring/src/predprocessing_lstm.py:63\n",
      "Создание последовательностей:   1%|          | 64/10000 [00:00<00:36, 272.74it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Configuration loaded successfully.\n",
      "Configuration loaded successfully.\n",
      "Configuration loaded successfully.\n",
      "Configuration loaded successfully.\n",
      "Configuration loaded successfully.\n",
      "Configuration loaded successfully.\n",
      "Configuration loaded successfully.\n",
      "Configuration loaded successfully.\n",
      "Configuration loaded successfully.\n",
      "Configuration loaded successfully.\n",
      "Configuration loaded successfully.\n",
      "Configuration loaded successfully.Configuration loaded successfully.\n",
      "\n",
      "Configuration loaded successfully.\n",
      "Configuration loaded successfully.\n",
      "Configuration loaded successfully.\n",
      "Configuration loaded successfully.\n",
      "Configuration loaded successfully.\n",
      "Configuration loaded successfully.\n",
      "Configuration loaded successfully.\n",
      "Configuration loaded successfully.Configuration loaded successfully.\n",
      "\n",
      "Configuration loaded successfully.\n",
      "Configuration loaded successfully.\n",
      "Configuration loaded successfully.\n",
      "Configuration loaded successfully.\n",
      "Configuration loaded successfully.\n",
      "Configuration loaded successfully.\n",
      "Configuration loaded successfully.\n",
      "Configuration loaded successfully.\n",
      "Configuration loaded successfully.\n",
      "Configuration loaded successfully.\n",
      "Configuration loaded successfully.Configuration loaded successfully.\n",
      "\n",
      "Configuration loaded successfully.\n",
      "Configuration loaded successfully.\n",
      "Configuration loaded successfully.\n",
      "Configuration loaded successfully.\n",
      "Configuration loaded successfully.\n",
      "Configuration loaded successfully.\n",
      "Configuration loaded successfully.\n",
      "Configuration loaded successfully.\n",
      "Configuration loaded successfully.\n",
      "Configuration loaded successfully.\n",
      "Configuration loaded successfully.\n",
      "Configuration loaded successfully.\n",
      "Configuration loaded successfully.\n",
      "Configuration loaded successfully.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Создание последовательностей:   2%|▏         | 192/10000 [00:02<02:05, 78.19it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Configuration loaded successfully.\n",
      "Configuration loaded successfully.\n",
      "Configuration loaded successfully.\n",
      "Configuration loaded successfully.\n",
      "Configuration loaded successfully.\n",
      "Configuration loaded successfully.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Создание последовательностей:   4%|▍         | 384/10000 [00:02<00:46, 205.78it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Configuration loaded successfully.\n",
      "Configuration loaded successfully.\n",
      "Configuration loaded successfully.\n",
      "Configuration loaded successfully.\n",
      "Configuration loaded successfully.\n",
      "Configuration loaded successfully.\n",
      "Configuration loaded successfully.\n",
      "Configuration loaded successfully.\n",
      "Configuration loaded successfully.\n",
      "Configuration loaded successfully.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Создание последовательностей: 100%|██████████| 10000/10000 [00:06<00:00, 1574.12it/s]\n",
      "2025-11-10 11:02:01,754 | my_logger - INFO - Созданы списки последовательностей: 10000 шт. | /data/aturov/scoring/src/predprocessing_lstm.py:79\n"
     ]
    }
   ],
   "source": [
    "# Создаем последовательности для validation\n",
    "Xn_val, Xc_val, y_val_seq, val_metadata, val_len = create_lstm_sequences_credit_scoring(\n",
    "    df=val_tab_full,\n",
    "    id_cols=id_cols,\n",
    "    numeric_cols=numeric_cols,\n",
    "    categorical_cols=categorical_cols,\n",
    "    cat_maps=cat_maps,\n",
    "    scaler=preprocessor, \n",
    "    seq_col=config.features.SEQ_COL,\n",
    "    target_col=config.features.TARGET_COL,\n",
    "    only_prediction=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "5efa1ee7",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-11-10 11:02:01,815 | my_logger - INFO - Val dataset: 10000 samples | /tmp/ipykernel_3121082/538504923.py:2\n",
      "2025-11-10 11:02:01,818 | my_logger - INFO - Sample batch dtypes: | /tmp/ipykernel_3121082/538504923.py:5\n",
      "2025-11-10 11:02:01,819 | my_logger - INFO -   X_num dtype: torch.float32 | /tmp/ipykernel_3121082/538504923.py:6\n",
      "2025-11-10 11:02:01,819 | my_logger - INFO -   X_cat dtype: torch.int64 | /tmp/ipykernel_3121082/538504923.py:7\n",
      "2025-11-10 11:02:01,819 | my_logger - INFO -   y dtype: torch.float32 | /tmp/ipykernel_3121082/538504923.py:8\n",
      "2025-11-10 11:02:01,821 | my_logger - INFO -   y values: tensor([0., 0., 0., 0.]) | /tmp/ipykernel_3121082/538504923.py:9\n",
      "2025-11-10 11:02:01,822 | my_logger - INFO - Val loader: 157 batches | /tmp/ipykernel_3121082/538504923.py:19\n"
     ]
    }
   ],
   "source": [
    "val_dataset = LSTMCreditScoringDataset(Xn_val, Xc_val, y_val_seq, val_len, val_metadata)\n",
    "logger.info(f\"Val dataset: {len(val_dataset)} samples\")\n",
    "# ← Проверяем типы данных в батче\n",
    "sample_batch = next(iter(DataLoader(val_dataset, batch_size=4)))\n",
    "logger.info(f\"Sample batch dtypes:\")\n",
    "logger.info(f\"  X_num dtype: {sample_batch['X_num'].dtype}\")\n",
    "logger.info(f\"  X_cat dtype: {sample_batch['X_cat'].dtype}\")\n",
    "logger.info(f\"  y dtype: {sample_batch['y'].dtype}\")\n",
    "logger.info(f\"  y values: {sample_batch['y']}\")\n",
    "\n",
    "va_loader_pred = DataLoader(\n",
    "    val_dataset,\n",
    "    batch_size=config.lstm.BATCH_SIZE,\n",
    "    shuffle=False,\n",
    "    collate_fn=collate_fn,\n",
    "    pin_memory=True\n",
    ")\n",
    "\n",
    "logger.info(f\"Val loader: {len(va_loader_pred)} batches\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "1428f25c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Перед инференсом\n",
    "model.eval()\n",
    "\n",
    "# Функция для получения предсказаний вероятностей из DataLoader\n",
    "val_probs   = _predict_probs_from_loader(va_loader_pred, model, device)\n",
    "assert len(val_probs) == len(val_dataset), \"Количество вероятностей не совпадает с числом примеров\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "123febb2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10000"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "meta_df_valid = val_dataset.metadata.copy()\n",
    "meta_df_valid = meta_df_valid.reset_index(drop=True)\n",
    "meta_df_valid['probability'] = val_probs.astype(float)\n",
    "# Предсказанные вероятности действуют с insert_datetime == CURRENT_DATE по  CURRENT_DATE + 7 дней\n",
    "meta_df_valid['insert_datetime'] = pd.to_datetime(CURRENT_DATE)\n",
    "meta_df_valid['observation_period_end_date'] = (pd.to_datetime(CURRENT_DATE) + pd.Timedelta(days=7)).date()  # date\n",
    "meta_df_valid['load_dt'] = pd.Timestamp.utcnow()\n",
    "\n",
    "# приведение типов под схему таблицы\n",
    "meta_df_valid['subs_id'] = meta_df_valid['subs_id'].astype('int64')\n",
    "meta_df_valid['ctn'] = meta_df_valid['ctn'].astype('int64')\n",
    "\n",
    "records = meta_df_valid[['subs_id','ctn','insert_datetime','probability',\n",
    "                         'observation_period_end_date','load_dt']].to_dict('records')\n",
    "len(records)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9217ffc8",
   "metadata": {},
   "source": [
    "## Загрузка предсказаний из модели в БД"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "005938f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sqlalchemy.orm import sessionmaker\n",
    "from src.base_models import InsertPredictionsScoring, Base  # класс уже описан тут: src/base_models.py\n",
    "\n",
    "# создать таблицу, если её ещё нет\n",
    "Base.metadata.create_all(clickhouse_engine)\n",
    "\n",
    "Session = sessionmaker(bind=clickhouse_engine)\n",
    "session = Session()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "ebe28d8a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>subs_id</th>\n",
       "      <th>ctn</th>\n",
       "      <th>probability</th>\n",
       "      <th>insert_datetime</th>\n",
       "      <th>observation_period_end_date</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>21694642</td>\n",
       "      <td>996774064937</td>\n",
       "      <td>0.474604</td>\n",
       "      <td>2025-11-10</td>\n",
       "      <td>2025-11-17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>21694615</td>\n",
       "      <td>996774064927</td>\n",
       "      <td>0.474604</td>\n",
       "      <td>2025-11-10</td>\n",
       "      <td>2025-11-17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>21694621</td>\n",
       "      <td>996774064929</td>\n",
       "      <td>0.474604</td>\n",
       "      <td>2025-11-10</td>\n",
       "      <td>2025-11-17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>21694609</td>\n",
       "      <td>996774064925</td>\n",
       "      <td>0.474604</td>\n",
       "      <td>2025-11-10</td>\n",
       "      <td>2025-11-17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>21694639</td>\n",
       "      <td>996774064936</td>\n",
       "      <td>0.474604</td>\n",
       "      <td>2025-11-10</td>\n",
       "      <td>2025-11-17</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    subs_id           ctn  probability insert_datetime  \\\n",
       "0  21694642  996774064937     0.474604      2025-11-10   \n",
       "1  21694615  996774064927     0.474604      2025-11-10   \n",
       "2  21694621  996774064929     0.474604      2025-11-10   \n",
       "3  21694609  996774064925     0.474604      2025-11-10   \n",
       "4  21694639  996774064936     0.474604      2025-11-10   \n",
       "\n",
       "  observation_period_end_date  \n",
       "0                  2025-11-17  \n",
       "1                  2025-11-17  \n",
       "2                  2025-11-17  \n",
       "3                  2025-11-17  \n",
       "4                  2025-11-17  "
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# быстрая массовая вставка\n",
    "session.execute(InsertPredictionsScoring.__table__.insert(), records)\n",
    "session.commit()\n",
    "\n",
    "# проверка\n",
    "check_df = pd.read_sql(\n",
    "    \"SELECT subs_id, ctn, probability, insert_datetime, observation_period_end_date \"\n",
    "    \"FROM data_science.credit_scoring_predictions \"\n",
    "    f\"WHERE insert_datetime = toDate('{CURRENT_DATE}') \"\n",
    "    \"ORDER BY insert_datetime DESC LIMIT 5\",\n",
    "    clickhouse_engine\n",
    ")\n",
    "check_df"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
